## Ãndice

1. [ğŸ–§ Sistema DistribuÃ­do de Armazenamento de Pares Chave-Valor](#sistema)  
2. [âš™ï¸ Funcionalidades principais](#funcionalidades)  
3. [ğŸ—ï¸ Arquitectura do sistema](#arquitetura) 
4. [ğŸ›ï¸ Diagrama de arquitetura do sistema](#diagrama) 
5. [ğŸ› ï¸ PrÃ©-requisitos](#requisitos) 
6. [ğŸ§ InstalaÃ§Ã£o e arranque Linux V1](#linux_v1) 
7. [ğŸ§ InstalaÃ§Ã£o e arranque Linux V2](#linux_v2) 
8. [ğŸ“¦ InstalaÃ§Ã£o e arranque Windows](#windows) 
9. [â˜ï¸ InstalaÃ§Ã£o e uso em cloud e standalone](#cloud) 
10. [ğŸ’» Demo Terminal (em caso da interface http://localhost/ apresentar algum erro)](#terminal) 
11. [ğŸŒ Demo Frontend](#frontend) 
12. [ğŸ“– Manual da API](#api) 
13. [ğŸ§ª Testes de carga com siege e build sem print de logs (modo detached) vs com print de logs](#siege)  
14. [ğŸ’‰ Testes de carga com ab e build sem print de logs (modo detached) vs com print de logs](#ab)  
15. [ğŸ“ Nota Importante dos testes de carga](#nota)  
16. [ğŸš€ Resultados tÃ­picos para grandes testes de carga](#resultados)
17. [ğŸ“• DocumentaÃ§Ã£o Complementar](#complementar)  
18. [ğŸ“„ LicenÃ§a](#licenca)

---

<h2 id="sistema">ğŸ–§ Sistema DistribuÃ­do de Armazenamento de Pares Chave-Valor</h2>

Um sistema distribuÃ­do de leitura e escrita de pares chave-valor, baseado em micro-serviÃ§os orquestrados por Docker Compose. Inclui:

- **Duas rÃ©plicas de API** (api1 e api2) em FastAPI  
- **Cache Redis** para aceleraÃ§Ã£o de leituras  
- **Base de dados PostgreSQL** para persistÃªncia  
- **RabbitMQ** como broker de mensagens durÃ¡veis (filas add_key e del_key)  
- **ServiÃ§o consumidor** que processa operaÃ§Ãµes em background  
- **Nginx** como proxy reverso e balanceador de carga  

---

<h2 id="funcionalidades">âš™ï¸ Funcionalidades principais</h2>

- **Cache-aside**: leituras vÃ£o primeiro ao Redis e, em caso de cache-miss, ao PostgreSQL, guardando depois em cache.  
- **Escrita/remoÃ§Ã£o assÃ­ncrona**: PUT/DELETE enfileiram mensagens no RabbitMQ; o consumer aplica insert/update/delete em PostgreSQL e atualiza o cache.  
- **Durabilidade e fiabilidade**: filas durÃ¡veis + mensagens persistentes + acknowledgements garantem que nenhuma operaÃ§Ã£o se perde, mesmo em falhas.  
- **OrdenaÃ§Ã£o e at-most-once**: cada mensagem inclui timestamp e apenas operaÃ§Ãµes mais recentes sÃ£o aplicadas.  
- **Escalabilidade horizontal**: basta aumentar rÃ©plicas de APIs ou de consumers conforme a carga.  

---

<h2 id="arquitetura">ğŸ—ï¸ Arquitectura do sistema</h2>

1. **FastAPI (api1 & api2)**  
   - Endpoints HTTP:  
     - `GET  /api?key=<chave>` â†’ devolve valor e origem (`redis` ou `postgres`)  
     - `GET  /api/all`           â†’ lista todos os pares  
     - `PUT  /api`               â†’ Coloca em fila operaÃ§Ã£o de escrita  
     - `DELETE /api`             â†’ Coloca em fila operaÃ§Ã£o de remoÃ§Ã£o  

2. **RabbitMQ**  
   - Filas durÃ¡veis `add_key` e `del_key`  
   - Mensagens com `delivery_mode=2` (persistentes) e timestamp  

3. **Consumer (workers)**  
   - LÃª filas em paralelo, com `basic_qos(prefetch_count=â€¦)`  
   - Aplica `INSERT â€¦ ON CONFLICT â€¦` ou `DELETE` em PostgreSQL  
   - Atualiza ou elimina entradas no Redis  

4. **Redis**  
   - Cache-aside de valores  
   - TTL definido pela aplicaÃ§Ã£o ou sem expiraÃ§Ã£o (conforme necessidade)  

5. **PostgreSQL**  
   - Tabela `kv_store(key TEXT PRIMARY KEY, value TEXT, last_updated TIMESTAMP)`  

6. **Nginx**  
   - Proxy reverso e balanÃ§o/gestao de carga entre `api1` e `api2`  

7. **Scaler**  
   - ServiÃ§o scale_monitor que vigia o uso de memÃ³ria RAM do sistema, para que, sempre que ultrapassa 70%, dispara automaticamente o arranque de rÃ©plicas adicionais das APIs, garantindo capacidade de processamento e continuidade de serviÃ§o.  

---

<h2 id="diagrama">ğŸ›ï¸ Diagrama de arquitetura do sistema</h2>

<p align="left">
  <img src="assets/diagrama_arquitetura.jpg" width="500" alt="diagrama_arquitetura.jpg">
</p>

- **Mais detalhes**:Ver [Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf) ("ImplementaÃ§Ãµes avaliadas - pag. 10")

---

<h2 id="requisitos">ğŸ› ï¸ PrÃ©-requisitos</h2>

- Docker & Docker Compose  
- Make  
- git
- (Opcional) `siege` ou `ab` para testes de carga  
- (Opcional) Em Windows, instalar Ubuntu

---

<h2 id="linux_v1">ğŸ§ InstalaÃ§Ã£o e arranque Linux V1</h2>

1. Clone o repositÃ³rio  
   ```bash
   git clone https://github.com/a74872/SPD

2. Ir para a pasta onde o clone foi realizado o clone
   ```bash
   cd SPD

3. Utilize o Makefile (recomendado)
   ```bash
   make

4. Ou manualmente
   ```bash
   docker-compose down --volumes
   docker-compose build --no-cache
   docker-compose up

5. Espere o build acabar, e aceda Ã  interface em: http://localhost/

> **Para mais detalhes** ver [Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf) ("AutomaÃ§Ã£o e reprodutibilidade - pag. 12").

---

<h2 id="linux_v2">ğŸ§ InstalaÃ§Ã£o e arranque Linux V2</h2>

1. Clone o repositÃ³rio  
   ```bash
   git clone https://github.com/a74872/SPD

2. Ir para a pasta onde o clone foi realizado o clone
   ```bash
   cd SPD

3. Utilize o ficheiro start.sh
   ```bash
   chmod +x start.sh
   ./start.sh

4. Ou manualmente
   ```bash
   docker-compose down --volumes
   docker-compose build --no-cache
   docker-compose up

5. Espere o build acabar, e aceda Ã  interface em: http://localhost/

> **Para mais detalhes** ver [Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf) ("AutomaÃ§Ã£o e reprodutibilidade - pag. 12").

---

<h2 id="windows">ğŸ“¦ InstalaÃ§Ã£o e arranque Windows</h2>

1. Clone o repositÃ³rio
   ```cmd
   git clone https://github.com/a74872/SPD
   cd SPD

2. Ir para a pasta onde o clone foi realizado o clone
   ```cmd
   cd SPD

3. Fazer Build
   ```cmd
   docker-compose down --volumes
   docker compose build --no-cache
   docker-compose up

4. Espere o build acabar, e aceda Ã  interface em: http://localhost/

> **Para mais detalhes** ver [Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf) ("AutomaÃ§Ã£o e reprodutibilidade - pag. 12").

---

<h2 id="cloud">â˜ï¸ InstalaÃ§Ã£o e uso em cloud e standalone</h2>

- **Este projeto** pode ser executado tanto em ambiente standalone (no seu PC de desenvolvimento Windows, macOS ou Linux) como em qualquer cloud provider (Google Cloud, AWS, Azure, DigitalOcean, â€¦), desde que disponha de uma mÃ¡quina virtual (VM) com Docker e Docker Compose instalados.

- **ImplantaÃ§Ã£o em ambiente cloud e criaÃ§Ã£o da VM :** Escolha o seu provider (GCP, AWS, Azure, DigitalOceanâ€¦). Crie uma instÃ¢ncia com SO Linux (Ubuntu/Debian) ou Windows Server. Garanta que tem pelo menos 2 vCPUs e 4 GB RAM para testes leves (ou mais para cargas elevadas).

- **Configurar a VM :** Abra SSH (Linux/macOS) ou RDP/PowerShell remota (Windows). Os restantes passos e prÃ©-requisitos (instalaÃ§Ã£o do Docker, Docker Compose, Makefile ou start.sh, clonagem do repositÃ³rio e comandos de arranque) jÃ¡ foram descritos anteriormente (acima) para os ambientes Windows e Linux.

---

<h2 id="terminal">ğŸ’» Demo Terminal (em caso da interface http://localhost/ apresentar algum erro)</h2>

- **Put**: 
Para inserir um par chave-valor no terminal utilize curl -X PUT http://localhost/api -H "Content-Type: application/json" -d '{"key":"minha_chave","value":"123"}' e obterÃ¡ de imediato {"status":"queued"} com cÃ³digo HTTP 200 OK, indicando que a operaÃ§Ã£o foi enfileirada; pode confirmar no pgAdmin4 ou em psql com SELECT * FROM kv_store; e verificar que a chave foi inserida.
1. Gravar um par chave-valor
   ```bash
   curl -X PUT http://localhost/api -H "Content-Type: application/json" -d '{"key":"minha_chave","value":"123"}'

- **Delete**: 
Para eliminar o par utilize curl -X DELETE http://localhost/api?key=minha_chave, que tambÃ©m retornarÃ¡ {"status":"queued"} com HTTP 200 OK, e depois confirme que a linha foi removida na tabela kv_store.
2. Eliminar um par chave-valor
   ```bash
   curl -X DELETE http://localhost/api?key=minha_chave

- **Get**: 
Para ler o valor dessa chave use curl http://localhost/api?key=minha_chave e receberÃ¡ {"data":{"key":"minha_chave","value":"123"},"source":"postgres"} (ou "redis" se tiver cache), mostrando de onde veio a resposta.
3. Ler um par chave-valor
   ```bash
   curl http://localhost/api?key=minha_chave

- **List**: 
Por fim, para listar todos os pares armazenados use curl http://localhost/api/all, que devolverÃ¡ {"data":[{"key":"outra_chave","value":"abc"},â€¦]}, e pode novamente comparar com o conteÃºdo da tabela no pgAdmin4 ou via psql.
4. Listar todos os pares chave-valor
   ```bash
   curl http://localhost/api/all

---

<h2 id="frontend">ğŸŒ Demo Frontend</h2>

- **Put**: 
Para inserir um novo par chave-valor atravÃ©s do frontend basta digitar no formulÃ¡rio o nome da chave e o valor (ambos strings) e clicar em â€œSalvarâ€. O frontend envia entÃ£o uma requisiÃ§Ã£o PUT para /api com um corpo JSON contendo os campos key e value, e devolve de imediato um HTTP 200 OK com {"status":"queued"}, indicando que a operaÃ§Ã£o foi enfileirada no RabbitMQ. Um serviÃ§o consumidor retira em background essa mensagem da fila add_key e executa o INSERT ou UPDATE na tabela kv_store do PostgreSQL (atualizando tambÃ©m o cache Redis, se existir). Por fim, para confirmar que a inserÃ§Ã£o decorreu com sucesso, abra o pgAdmin4 (ou ligue-se via psql) Ã  base de dados bd_spd e consulte a tabela kv_store â€“ se encontrar a linha com a chave e o valor indicados, significa que o par foi efetivamente gravado.
<p align="center">
  <img src="assets/put.jpg" width="600" alt="put.jpg">
</p>

- **Get**: 
Para efetuar uma leitura (GET) de um par chave-valor, basta introduzir o nome da chave no campo de pesquisa e premir â€œPesquisarâ€. O frontend envia imediatamente uma requisiÃ§Ã£o GET para /api?key=<nome_da_chave>; se o valor estiver no cache Redis, recebe de imediato HTTP 200 OK com {"data":{"key":"<nome_da_chave>","value":"<valor>"},"source":"redis"}; em caso de cache miss, a API vai ao PostgreSQL, retorna o valor e guarda-o no Redis para consultas futuras, respondendo tambÃ©m com HTTP 200 OK e "source":"postgres". Para confirmar, abra o pgAdmin4 (ou use psql) e verifique se a linha existe na tabela kv_store ou volte a fazer GET para a mesma chave e observe "source":"redis" no resultado.
<p align="center">
  <img src="assets/get_1.jpg" width="600" alt="get_1.jpg">
</p>

<p align="center">
  <img src="assets/get_2.jpg" width="600" alt="get_2.jpg">
</p>

- **Delete**: 
Para eliminar um par chave-valor, escreva o nome da chave no campo correspondente e clique em â€œEliminarâ€. O frontend dispara uma requisiÃ§Ã£o DELETE para /api?key=<nome_da_chave> e devolve de imediato HTTP 200 OK com {"status":"queued"}, sinalizando que a operaÃ§Ã£o foi enfileirada em del_key. O consumidor processa essa mensagem em background, remove a entrada da tabela kv_store no PostgreSQL e invalida a chave no Redis. Para verificar a exclusÃ£o, recorra ao pgAdmin4 (ou psql) e confirme que a linha jÃ¡ nÃ£o estÃ¡ presente, ou faÃ§a um GET para essa chave e receba HTTP 404 Not Found.
<p align="center">
  <img src="assets/delete.jpg" width="600" alt="delete.jpg">
</p>

<p align="center">
  <img src="assets/delete_confirmation.jpg" width="600" alt="delete_confirmation.jpg">
</p>

- **List**: 
Para listar todos os pares chave-valor, basta carregar no botÃ£o â€œListar tudoâ€ no frontend, que envia uma Ãºnica requisiÃ§Ã£o GET para /api/all; a API responderÃ¡ com status 200 OK e um JSON contendo o array de objetos com cada key e value, e o frontend renderiza imediatamente essa lista (por exemplo, numa tabela), pelo que, para confirmar, pode igualmente abrir o pgAdmin4 ou usar psql com SELECT * FROM kv_store; e verificar que os resultados no banco coincidem com os apresentados.
<p align="center">
  <img src="assets/list.jpg" width="400" alt="list.jpg">
</p>

---

<h2 id="api">ğŸ“– Manual da API</h2>

- **Ver** [ğŸ’» Demo Terminal](#terminal) â•â•â•

---

<h2 id="siege">ğŸ§ª Testes de carga com siege e build sem print de logs (modo detached) vs com print de logs</h2>

- **Siege**: Ver o ficheiro [commands_siege.txt](siege/commands_siege.txt) e [urls.txt](siege/urls.txt)
- **Resultados sem print de logs**: Em apenas cerca de 11min (693,86 segundos) foram processadas 1 632 000 requisiÃ§Ãµes com o Siege, mantendo 0 perdas de dados, o que traduz um throughput mÃ©dio de cerca de 2 351 req/s. Estes resultados assentam em vÃ¡rios factores de optimizaÃ§Ã£o: as APIs correm em modo detached (docker compose up -d), eliminando o overhead de I/O de logs em tempo real; o basic_qos(prefetch_count=50) no consumidor garante elevado dÃ©bito sem riscos de mensagem perdida; as ligaÃ§Ãµes ao RabbitMQ e ao PostgreSQL sÃ£o reutilizadas, evitando o custo de abrir e fechar conexÃµes a cada operaÃ§Ã£o; e a estratÃ©gia cache-aside com Redis (no caso do get) reduz drasticamente a latÃªncia das leituras repetidas. No seu conjunto, estas escolhas permitem ao sistema escalar de forma linear sob cargas massivas, mantendo latÃªncias controladas e fiabilidade total, exemplo de grafico na figura da esquerda.
---
- **Resultados com print de logs**: Em cerca de 18min e no modo â€œforegroundâ€, com todos os logs a serem enviados em tempo real para o terminal, o sistema processou apenas 204 000 requisiÃ§Ãµes em 1 116,8 s (â‰ˆ 182,6 req/s), demonstrando um tronco de desempenho significativamente inferior ao cenÃ¡rio detached. Esta lentidÃ£o prende-se sobretudo com o overhead de I/O de logging: cada print() da aplicaÃ§Ã£o, cada registo de acesso do Nginx/UVicorn/RabbitMQ percorre o pipeline de buffers, parsing e flushing para o terminal, criando um verdadeiro ponto de estrangulamento que retarda o processamento das requisiÃ§Ãµes. AlÃ©m disso, o multiplexing contÃ­nuo dos streams de saÃ­da e as sincronizaÃ§Ãµes de buffer contribuem para aumentar a latÃªncia geral. Apesar de manter zero perdas de dados, este modo revela como o custo de logging em tempo real pode degradar severamente o throughput, passando de mais de 2 351 req/s em detached para cerca de 183 req/s com logs ativos, exemplo de grafico na figura da direita.

<p align="center">
  <img src="assets/siege_com_d.jpg" width="550" alt="siege_com_d.jpg"> <img src="assets/siege_sem_d.jpg" width="541" alt="siege_sem_d.jpg">,
</p>

---

<h2 id="ab">ğŸ’‰ Testes de carga com ab e build sem print de logs (modo detached) vs com print de logs</h2>

- **ApacheBench**: Ver o ficheiro [commands_ab.txt](ab/commands_ab.txt) e [body.txt](ab/body.txt)
- **Resultados sem print de logs**: Em cerca de 12min (727,89 segundos) o ApacheBench processou 1 632 000 requisiÃ§Ãµes com 255 clientes concorrentes, mantendo 0 perdas de dados, o que corresponde a um throughput mÃ©dio de aproximadamente 2 241 requisiÃ§Ãµes por segundo. Estes resultados foram alcanÃ§ados graÃ§as a vÃ¡rias otimizaÃ§Ãµes: as APIs foram executadas em modo detached (docker compose up -d), eliminando o overhead de I/O associado ao streaming de logs em tempo real; foi configurado basic_qos(prefetch_count=50) no consumidor para maximizar o dÃ©bito sem comprometer a fiabilidade das mensagens; as ligaÃ§Ãµes TCP ao RabbitMQ e ao PostgreSQL sÃ£o mantidas abertas e reutilizadas, evitando custos de estabelecimento de conexÃ£o em cada operaÃ§Ã£o; e a estratÃ©gia cache-aside com Redis (no caso do get) aliviou significativamente a carga de leituras no PostgreSQL, reduzindo as latÃªncias. Em conjunto, estes fatores permitem ao sistema lidar com elevados nÃ­veis de concorrÃªncia mantendo a latÃªncia sob controlo e garantindo 100 % de consistÃªncia dos dados, exemplo de grafico na figura da esquerda.

- **Resultados com print de logs**: Em modo foreground, utilizando o comando ab -p body.txt -T "application/json" -s 500 -c 255 -n 100000 -m PUT http://localhost/api,conseguimos completar as 100 000 requisiÃ§Ãµes em 593,927 segundos (â‰ˆ 168 req/s). Foi necessÃ¡rio especificar -s 500 porque, por omissÃ£o, o ab abortava o teste antes de chegar Ã s 100 000 requisiÃ§Ãµes, acusando um timeout nos sockets. No output, vÃª-se que o ab processou com sucesso os primeiros lotes de 10 000 e 20 000 pedidos, mas depois exibiu a mensagem, "apr_pollset_poll: The timeout specified has expired (70007)" e "Total of 23437 requests completed", que indica que a operaÃ§Ã£o de leitura/escrita em socket demorou mais do que o limite interno (cerca de 20 s) e o teste foi interrompido apÃ³s 23 437 requisiÃ§Ãµes. Em resumo, o servidor nÃ£o estava a responder rÃ¡pido o suficiente ao ritmo imposto pelo ApacheBench, levando ao abortamento prematuro. A soluÃ§Ã£o passou por aumentar o timeout com -s, ajustar parÃ¢metros de carga (concorrÃªncia e total de requisiÃ§Ãµes) ou, idealmente, optimizar o sistema â€” por exemplo, executando as APIs em modo detached (sem streaming de logs), reutilizando ligaÃ§Ãµes persistentes a RabbitMQ e PostgreSQL, e escalonando rÃ©plicas de API para suportar a carga desejada, exemplo de grafico na figura da direita.

<p align="center">
  <img src="assets/ab_com_d.jpg" width="556" alt="ab_com_d.jpg"> <img src="assets/ab_sem_d.jpg" width="550" alt="ab_sem_d.jpg">,
</p>

---

<h2 id="nota">ğŸ“ Nota Importante dos testes de carga</h2>

Durante os testes de carga verificÃ¡mos que executar o sistema em modo â€œforegroundâ€ (i.e. **docker compose up** sem -d) introduz um overhead de I/O que impacta diretamente o desempenho. Cada log enviado para o terminalâ€”print()s da aplicaÃ§Ã£o, mensagens do Nginx, UVicorn e RabbitMQâ€”obriga a mÃºltiplas operaÃ§Ãµes de flush, parsing e formataÃ§Ã£o, consumindo CPU e I/O de disco. Quando geramos centenas ou milhares de logs por segundo, o prÃ³prio terminal se torna um fator limitador, impondo throttling e constantes sincronizaÃ§Ãµes de buffer para nÃ£o perder saÃ­da, o que retarda significativamente o processamento de pedidos.

Em contrapartida, ao usar **docker compose up -d**, os containers correm em background sem despejar logs para o terminal, eliminando esse overhead de I/O. Nos nossos benchmarks, isso traduziu-se em throughput muito mais elevado e latÃªncias menores â€” prova de que a forma como gerimos o logging Ã© um factor crÃ­tico a ter em conta em cenÃ¡rios de alta carga.

---

<h2 id="resultados">ğŸš€ Resultados tÃ­picos para grandes testes de carga c/ e s/ modo detached :</h2>

- 1 632 000 de pedidos sem perda de mensagens (com basic_qos(prefetch_count=50)).
- Tempo de processamento reduzido de 45min para 7min apÃ³s optimizaÃ§Ã£o de conexÃµes.
- **RabitMQ**: Pode ver e gerir em tempo real praticamente tudo o que se passa no broker: http://localhost:15672/#/
- **Mais dados**:Ver [Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf) ("DiscussÃ£o de Resultads - pag. 14")

<p align="left">
  <img src="assets/teste_carga_million.jpg" width="300" alt="teste_carga_million.jpg"> <img src="assets/siege_carga_sem_d.jpg" width="314" alt="siege_carga_sem_d.jpg"> <img src="assets/ab_carga_com_d.jpg" width="350" alt="ab_carga_com_d.jpg"> <img src="assets/ab_carga_sem_d.jpg" width="350" alt="ab_carga_sem_d.jpg">
</p>

---

<h2 id="complementar">ğŸ“• DocumentaÃ§Ã£o Complementar</h2>

[Sistemas_Distribuidos.pdf](Sistemas_Distribuidos.pdf)

**O PDF** comeÃ§a por uma IntroduÃ§Ã£o, onde se expÃµe o problema do armazenamento distribuÃ­do de pares chave-valor e os objetivos do projeto. Segue-se o Enquadramento, que contextualiza o trabalho em termos de sistemas paralelos e distribuÃ­dos, apresentando brevemente conceitos de processamento distribuÃ­do, as ferramentas e compiladores usados (Docker, Python, PostgreSQL, RabbitMQ, Redis, FastAPI) e o papel das APIs como interface REST. Depois, sÃ£o descritas as mÃ©tricas de avaliaÃ§Ã£o (ApacheBench e Siege) e justifica-se a escolha de dimensÃµes para o caso de estudo (nÃºmero de clientes, volume de mensagens, latÃªncias aceitÃ¡veis).

No capÃ­tulo de Metodologia Experimental detalha-se o ambiente de testes (hardware, software, configuraÃ§Ã£o Docker Compose), as implementaÃ§Ãµes avaliadas (cada componente do sistema: APIs, cache, filas, consumer, base de dados, proxy e o prÃ³prio scaler de RAM), as prÃ¡ticas de automaÃ§Ã£o e reprodutibilidade (Infrastructure as Code, Makefile, healthchecks) e o procedimento de mediÃ§Ã£o (como foram executados os benchmarks, que parÃ¢metros foram variÃ¡veis e quais ficaram fixos).

Em DiscussÃ£o dos Resultados, analisam-se os padrÃµes de tempo de execuÃ§Ã£o real, a aceleraÃ§Ã£o obtida ao desligar o logging em foreground, a eficiÃªncia do cache-aside e do prefetch no RabbitMQ, a escalabilidade prevista (linear ao adicionar rÃ©plicas) e o impacto da carga no comportamento geral do sistema. As conclusÃµes da discussÃ£o sintetizam como as decisÃµes de arquitetura contribuÃ­ram para fiabilidade total e baixas latÃªncias, mesmo sob mais de um milhÃ£o de requisiÃ§Ãµes.

Finalmente, na ConclusÃ£o, recapitula-se a solidez da soluÃ§Ã£o implementada e apontam-se possÃ­veis melhorias futuras, e o documento encerra com as ReferÃªncias que suportaram o estudo.

---

<h2 id="licenca">ğŸ“„ LicenÃ§a</h2>

- Este projecto estÃ¡ licenciado sob Vasile's Rules.
- Desenvolvido por Vasile Karpa â€“ 2025
- Contacto: a74872@ualg.pt